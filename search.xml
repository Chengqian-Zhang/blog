<?xml version="1.0" encoding="utf-8"?><search><entry><title>The DeepModeling Manifesto</title><url>/blog/manifesto/</url><content><![CDATA[The integration of machine learning and physical modeling is changing the paradigm of scientific research. Those who hope to extend the frontier of science and solve challenging practical problems through computational modeling are coming together in new ways never seen before. This calls for a new infrastructure--new platforms for collaboration, new codingframeworks, new data processing schemes, and new ways of using the computing power.  It also calls for a new culture—the culture of working together closely for the benefit of all, of free exchange and sharing of knowledge and tools, of respect and appreciation of each other&#39;s work, and of the pursuit of harmony among diversity.
The DeepModeling community is a community of such a group of people.


What is DeepModeling?The two most important applications of computing are machine learning and physical modeling. The former is an effective tool for analyzing complex data; the latter is a scientific description of the physical world. The vitality boosted by the effective integration of the two is changing all aspects of scientific research. DeepModeling will ultimately be a set of methodologies and tools that combine machine learning, physical modeling, and cutting-edge computational platforms. People who are attracted by the DeepModeling community are attracted by its open, inclusive environment, as well as its dedication to the cause of advancing scientific computing worldwide.
Why choose open source?There are different interpretations of the term &quot;open source&quot;. The consensus among the DeepModeling community is that open source is a collaborative software development platform based on the spirit of openness and sharing. Open source is a familiar concept for people in the fields of machine learning and computer science, but it is not yet popular in the field of scientific computing. What we advocate is that an algorithm or software should not be judged by the reputation of the journal in which it is published, but by its ability to solve real world problems and its actual contribution to science. The sustainable development of a software requires continuous investment in manpower. It should undergo incremental improvement, and it should be put to the test of solving real-world problems in an open environment. This is often difficult to achieve by individuals or individual groups. The open-source community provides better solutions. 
The history of the DeepModeling communityThe &quot;DeepModeling Community&quot; started with the initiation of the &quot;deepmd-kit&quot; project. “deepmd-kit&quot; is a software tool that combines machine learning and molecular dynamics, which helps to overcome a long-standing difficulty in the field of molecular dynamics, namely the dilemma of having to choose between efficiency and accuracy. The name &quot;DeepModeling&quot; was proposed by early developers of the deepmd-kit project, with the intention of using deep learning tools to solve the curse of dimensionality problem in multi-scale modeling. DeepModeling has therefore become the name of the GitHub organization (https://github.com/deepmodeling) which manages the original deepmd-kit project. After the development of deepmd-kit, the DeepModeling community has successively initiated projects such as dpdata, dp-gen, and dpdispatcher, and extended the modeling scale to electronic structure level through projects such as deepks-kit and ABACUS. These projects have brought together people from all over the world working on molecular simulations. 
The short-term plan and long-term vision of the DeepModeling communityIn the short term, developers in the DeepModeling community will focus on  atomic-scale simulation methods and tools. This includes solving the many-body Schrödinger equation, electronic structure calculation, molecular dynamics simulation, and coarse-grained molecular dynamics simulation. This also includes tasks such as data generation, model training, high-performance optimization, etc. In addition, it includes different workflows and management tools, as well as computing power scheduling tools for different systems, different scenarios, and different purposes. 
It should be pointed out that the combination of physical modeling and machine learning often fundamentally changes the implementation logic of a piece of software. Therefore, the new infrastructure will not be settled once and for all, but will be gradually improved through an iterative process and  upgrades from time to time.
In the long run, the DeepModeling community is committed to combining physical models at all scales with machine learning methods, using the most cutting-edge computing platforms to solve the most challenging scientific and technological problems faced by the human society.
How can you contribute? If you want to contribute to an existing project in the DeepModeling community, please just do so or contactthe corresponding developer directly; if you want to open a new project in the DeepModeling community, or if you want the DeepModeling community to help develop your project, just contact &#x63;&#111;&#110;&#116;&#97;&#99;&#116;&#64;&#x64;&#101;&#x65;&#x70;&#109;&#111;&#100;&#101;&#108;&#x69;&#x6e;&#103;&#x2e;&#111;&#114;&#103;.
If you are a programmer who loves science and is attracted by the future scientific computing platform built by the DeepModeling community, you can contribute not only through new algorithms, but also code development specifications, document writing specifications, community databases, task scheduling, workflow management and other tools.  In addition, you can contribute to code architecture design and high-performance optimization tasks in the DeepModeling community. People in the field of scientific computing will greatly appreciate your expertise and contribution.
If you are a hardcore developer familiar with topics such as electronic structure calculations, molecular dynamics, and finite element methods, the DeepModeling community will be your place to showcase your talents. The addition of machine learning components requires us to rethink about architecture design, each specific implementation for the tasks mentioned above and high-performance optimization. You will become important bridges that connect other developers, contributors, and users in different areas.
If you have only used some basic scientific software and have worked on some post-processing scripts, the DeepModeling community also needs you. Try to ask questions and communicate on github&#x2F;gitee and other communication platforms, try to give opinions, and try to fork, commit, pr... Your little by little contribution will make the DeepModeling community better and better, and the DeepModeling community will be very grateful for such contributions.
Even if you are just a bystander, if you support the concept of the DeepModeling community, your recognition and dissemination will also be a great encouragement and support for the DeepModeling community.
Final remarksDespite the tremendous advances in AI and computing power, the scientific computing community is largely embedded in an old-fashioned culture. Many of the most important tasks rely on legacy codes. The core algorithms used in many commercial software have been outdated. The self-sufficient style of work is similar to that of the agricultural agesresulting in poor efficiency. It is only in recent years that some promising open-source communities have emerged. However, these communities are often aimed at specific tools for specific scales, and are often maintained by specific academic research groups. They face serious challenges in terms of continuous development and improved user experience.
The DeepModeling project promises to change all that. 
The combination of machine learning and physical modeling calls for a new paradigm, the open-source community paradigm. Such a paradigm has long been embraced in the computer and electronics industry, with Linux and Andriod being the very well-known examples. In this sense, what the DeepModeling project does is to borrow these ideas and use them for scientific computing. For people in computational science and engineering, efficient and reusable modeling tools that can be continuously improved will free researchers from the plight of no model or with only ad hoc models. For those who work on machine learning, the world of physical models will provide a relatively new and surely vast playground. Working together as an open-source community will make our work more productive, up to date, reliable, and transparent. The spirit of close collaboration, of respect and building on each other’s work will surely inspire more and more people to join the cause of advancing computing for the benefit of the human society. This is an exciting opportunity. This is the future of scientific computing!
]]></content></entry><entry><title>DP Tutorial 1: How to Setup a DeePMD-kit Training within 5 Minutes?</title><url>/blog/tutorial1/</url><content><![CDATA[DeePMD-kit is a software to implement Deep Potential. There is a lot of information on the Internet, but there are not so many tutorials for the new hand, and the official guide is too long. Today, I&#39;ll take you 5 minutes to get started with DeePMD-kit. 
Let&#39;s take a look at the training process of DeePMD-kit:

graph LR
A[Prepare data] --&gt; B[Training]
B --&gt; C[Freeze the model]


What? Only three steps? Yes, it&#39;s that simple. 

Preparing data is converting the computational results of DFT to data that can be recognized by the DeePMD-kit. 
Training is train a Deep Potential model using the DeePMD-kit with data prepared in the previous step. 
Finally, what we need to do is to freeze the restart file in the training process into a model, in other words is to extract the neural network parameters into a file for subsequent use. I believe you can&#39;t wait to get started. Let&#39;s go!

1. Preparing DataThe data format of the DeePMD-kit is introduced in the official document but seems complex. Don&#39;t worry, I&#39;d like to introduce a data processing tool: dpdata! You can use only one line Python scripts to process data. So easy!
import dpdatadpdata.LabeledSystem(&#x27;OUTCAR&#x27;).to(&#x27;deepmd/npy&#x27;, &#x27;data&#x27;, set_size=200)

In this example, we converted the computational results of the VASP in the OUTCAR to the data format of the DeePMD-kit and saved in to a directory named data, where npy is the compressed format of the numpy, which is required by the DeePMD-kit training. We assume OUTCAR stores 1000 frames of molecular dynamics trajectory, then where will be 1000 points after converting. set_size=200 means these 1000 points will be divided into 5 subsets, which is named as data/set.000~data/set.004, respectively. The size of each set is 200. In these 5 sets, data/set.000~data/set.003 will be considered as the training set by the DeePMD-kit, and data/set.004 will be considered as the test set. The last set will be considered as the test set by the DeePMD-kit by default. If there is only one set, the set will be both the training set and the test set. (Of course, such test set is meaningless.) 
2. TrainingIt&#39;s required to prepare an input script to start the DeePMD-kit training. Are you still out of the fear of being dominated by INCAR script?  Don&#39;t worry, it&#39;s much easier to configure the DeePMD-kit than configuring the VASP. First, let&#39;s download an example and save to input.json:
wget https://raw.githubusercontent.com/deepmodeling/deepmd-kit/v1.3.3/examples/water/train/water_se_a.json -O input.json

The strength of the DeePMD-kit is that the same training parameters are suitable for different systems, so we only need to slightly modify input.json to start training. Here is the first parameter to modify:
&quot;type_map&quot;:     [&quot;O&quot;, &quot;H&quot;],

In the DeePMD-kit data, each atom type is numbered as an integer starting from 0. The parameter gives an element name to each atom in the numbering system. Here, we can copy from the content of data/type_map.raw. For example,
&quot;type_map&quot;:    [&quot;A&quot;, &quot;B&quot;,&quot;C&quot;],

Next, we are going to modify the neighbour searching parameter:
&quot;sel&quot;:       [46, 92],

Each number in this list gives the maximum number of atoms of each type among neighbor atoms of an atom. For example, 46 means there are at most 46 O (type 0) neighbours. Here, our elements were modified to A, B, and C, so this parameters is also required to modify. What to do if you don&#39;t know the maximum number of neighbors? You can be roughly estimate one by the density of the system, or try a number blindly. If it is not big enough, the DeePMD-kit will shoot WARNINGS.  Below we changed it to 
&quot;sel&quot;:       [64, 64, 64]

In addtion, we need to modify
&quot;systems&quot;:     [&quot;../data/&quot;],

to
&quot;systems&quot;:     [&quot;./data/&quot;],

It is because that the directory to write to is ./data/ in the current directory. Here I&#39;d like to introduce the definition of the data system. The DeePMD-kit considers that data with corresponding element types and atomic numbers form a system. Our data is generated from a molecular dynamics simulation and meets this condition, so we can put them into one system. Dpdata works the same way. If data cannot be put into a system, multiple systems is required to be set as a list here:
&quot;training&quot;: &#123;       &quot;systems&quot;: [&quot;system1&quot;, &quot;system2&quot;]

Finnally, we are likely to modify another two parameters:
&quot;stop_batch&quot;:   1000000,&quot;batch_size&quot;:   1,
stop_batch is the numebr of training step using the SGD method of deep learning, and batch_size is the mini-batch size of data in each step.If we want to reduce stop_batch and use batch_size that the DeePMD-kit recommends, we can use
&quot;stop_batch&quot;:   500000,&quot;batch_size&quot;:   &quot;auto&quot;,

Now we have succesfully set a input file! To start training, we execuate
dp train input.json

and wait for results. During the training process, we can see lcurve.out to observe the error reduction.Among them, Column 4 and 5 are the test and training errors of energy (normalized by the number of atoms), and Column 6 and 7 are the test and training errors of the force. 
3. Freeze the ModelAfter training, we can use the following script to freeze the model:
dp freeze

The default filename of the output model is frozen_model.pb. As so, we have got a good or bad DP model. As for the reliability of this model and how to use it, I will give you a detailed tutorial in the next post.
]]></content><categories><category>tutorial</category></categories><tags><tag>DeePMD-kit</tag></tags></entry><entry><title>DP Tutorial 2: DeePMD-kit: Install with Conda &amp; Offline Packages &amp; Docker</title><url>/blog/tutorial2/</url><content><![CDATA[Do you prepare to read a long article before clicking the tutorial? Since we can teach you how to setup a DeePMD-kit training in 5 minutes, we can also teach you how to install DeePMD-kit in 5 minutes. The installation manual will be introduced as follows:
Install with condaAfter you install conda, you can install the CPU version with the following command:
conda install deepmd-kit=*=*cpu lammps-dp=*=*cpu -c deepmodeling

To install the GPU version containing CUDA 10.1:
conda install deepmd-kit=*=*gpu lammps-dp=*=*gpu -c deepmodeling

If you want to use the specific version, just replace * with the version:
conda install deepmd-kit=1.3.3=*cpu lammps-dp=1.3.3=*cpu -c deepmodeling

Install with offline packagesDownload offline packages in the Releases page, or use wget:
wget https://github.com/deepmodeling/deepmd-kit/releases/download/v1.3.3/deepmd-kit-1.3.3-cuda10.1_gpu-Linux-x86_64.sh -O deepmd-kit-1.3.3-cuda10.1_gpu-Linux-x86_64.sh

Take an example of v1.3.3. Execuate the following commands and just follow the prompts.
sh deepmd-kit-1.3.1-cuda10.1_gpu-Linux-x86_64.sh

With DockerTo pull the CPU version:
docker pull ghcr.io&#x2F;deepmodeling&#x2F;deepmd-kit:1.2.2_cpuTo pull the GPU version:
docker pull ghcr.io&#x2F;deepmodeling&#x2F;deepmd-kit:1.2.2_cuda10.1_gpu
Tipsdp is the program of DeePMD-kit and lmp is the program of LAMMPS.
dp -hlmp -h

GPU version has contained CUDA Toolkit. Note that different CUDA versions support different NVIDIA driver versions. See NVIDIA documents for details.
Don&#39;t hurry up and try such a convenient installation process. But I still want to remind everyone that the above installation methods only support the official version released by DeePMD-kit. If you need to use the devel version, you still need to go through a long compilation process. Please refer to the installation manual.
]]></content><categories><category>tutorial</category></categories><tags><tag>DeePMD-kit</tag></tags></entry></search>